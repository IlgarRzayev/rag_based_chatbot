{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. GeliÅŸtirme OrtamÄ± (Kurulum)**\n",
        "\n",
        "Proje iÃ§in gerekli tÃ¼m kÃ¼tÃ¼phaneler yÃ¼klenmektedir.\n",
        "LangChain, FAISS, Gemini API ve Gradio bileÅŸenleri RAG tabanlÄ± chatbot iÃ§in gereklidir."
      ],
      "metadata": {
        "id": "_I78joAY3ljI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYkyf6MOgnpb"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-generativeai langchain langchain-community faiss-cpu sentence-transformers langchain-google-genai datasets huggingface_hub pyarrow gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. API ve ModÃ¼l Kurulumu**\n",
        "\n",
        "Bu hÃ¼crede gerekli modÃ¼ller import edilmekte ve Google Gemini ile Hugging Face API anahtarlarÄ± tanÄ±mlanmaktadÄ±r.\n",
        "APIâ€™ler, modelin metin Ã¼retimi ve embedding oluÅŸturmasÄ± iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "TXajf2Au4Nlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from datasets import load_dataset\n",
        "from google.colab import userdata\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "except:\n",
        "    print(\"Secrets bulunamadÄ±\")\n",
        "\n",
        "os.environ['HUGGINGFACE_HUB_TOKEN'] = HF_TOKEN\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "Il9vw9tNidzS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Veri Seti HazÄ±rlama**\n",
        "\n",
        "Bu hÃ¼crede â€œaliarda/Turkish-Poems-19Kâ€ adlÄ± TÃ¼rkÃ§e ÅŸiir veri seti Hugging Faceâ€™ten yÃ¼klenmektedir.\n",
        "siir_metni sÃ¼tunundaki ilk 1000 ÅŸiir alÄ±narak modelin Ã¶ÄŸrenmesi iÃ§in kullanÄ±lmaktadÄ±r."
      ],
      "metadata": {
        "id": "cZJddFjz4dwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"aliarda/Turkish-Poems-19K\", token=HF_TOKEN)\n",
        "print(f\"Veri seti yÃ¼klendi! Toplam {len(dataset['train'])} ÅŸiir bulundu.\")\n",
        "\n",
        "poems = [\n",
        "    item[\"siir_metni\"].strip()\n",
        "    for item in dataset[\"train\"]\n",
        "    if item[\"siir_metni\"] and isinstance(item[\"siir_metni\"], str) and item[\"siir_metni\"].strip()\n",
        "]\n",
        "poems = poems[:1000]\n",
        "print(f\"{len(poems)} ÅŸiir iÅŸleme alÄ±ndÄ±.\")"
      ],
      "metadata": {
        "id": "CfVmQUMJiq2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Embedding ve VektÃ¶r VeritabanÄ± (FAISS)**\n",
        "\n",
        "Bu aÅŸamada ÅŸiirler embedding (vektÃ¶r temsili) haline getirilir ve FAISS veritabanÄ±na kaydedilir.\n",
        "FAISS, metin benzerliÄŸini hÄ±zlÄ± hesaplamak iÃ§in kullanÄ±lÄ±r.\n",
        "Her ÅŸiir parÃ§asÄ± 300 karakterlik kÃ¼Ã§Ã¼k bÃ¶lÃ¼mlere ayrÄ±lÄ±r."
      ],
      "metadata": {
        "id": "tU74Zzu54sy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "\n",
        "docs = []\n",
        "for p in poems:\n",
        "    if p and isinstance(p, str) and p.strip():\n",
        "        docs.extend(text_splitter.create_documents([p.strip()]))\n",
        "\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "print(\"âœ… FAISS veritabanÄ± oluÅŸturuldu!\")"
      ],
      "metadata": {
        "id": "RoQ9KrWkitu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. RAG Zinciri ve LLM Modeli**\n",
        "\n",
        "Bu bÃ¶lÃ¼mde Gemini 2.5 Pro modeli kullanÄ±larak LangChain tabanlÄ± bir RAG zinciri oluÅŸturulur.\n",
        "KullanÄ±cÄ±nÄ±n girdiÄŸi temaya gÃ¶re, veri tabanÄ±ndaki benzer ÅŸiirlerden esinlenerek yeni bir ÅŸiir Ã¼retilir."
      ],
      "metadata": {
        "id": "7xSEiBIs5FEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0.8\n",
        ")\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "print(\"Sistem hazÄ±r! Åiir Ã¼retmeye hazÄ±rsÄ±nÄ±z\")\n"
      ],
      "metadata": {
        "id": "fmF_wxVfiv8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Gradio ArayÃ¼zÃ¼**\n",
        "\n",
        "Bu hÃ¼cre, Gradio kullanarak etkileÅŸimli bir web arayÃ¼zÃ¼ oluÅŸturur.\n",
        "KullanÄ±cÄ± ÅŸiir temasÄ±nÄ± yazar, sistem RAG modeliyle yeni bir TÃ¼rkÃ§e ÅŸiir Ã¼retir."
      ],
      "metadata": {
        "id": "okIYVBJL5QPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def siir_uretici(tema):\n",
        "    prompt = f\"\"\"TÃ¼rkÃ§e, sanatsal ve kafiyeli bir ÅŸiir yaz.\n",
        "    Åiir ÅŸu temaya uygun olmalÄ±: '{tema}'.\n",
        "    Veri tabanÄ±ndaki TÃ¼rkÃ§e ÅŸiirlerin tarzÄ±ndan esinlen:\n",
        "    Åiir Ã¶zellikleri:\n",
        "    - Her dize kÄ±sa olsun (4â€“8 kelime arasÄ±)\n",
        "    - Son kelimelerde kafiye uyumu bulunsun\n",
        "    - Gerekirse iÃ§ uyak (iÃ§ kafiye) da kullanÄ±labilir\n",
        "    - AkÄ±cÄ±, duygusal ve imgelerle dolu olsun\n",
        "    - DoÄŸa ve insan temalarÄ± kullanÄ±labilir\n",
        "    - Sadece ÅŸiiri yaz, aÃ§Ä±klama yapma.\n",
        "    \"\"\"\n",
        "\n",
        "    response = qa_chain.invoke({\"question\": prompt, \"chat_history\": []})\n",
        "    return response[\"answer\"].strip()\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=siir_uretici,\n",
        "    inputs=gr.Textbox(\n",
        "        label=\"ğŸ­ Åiir TemasÄ±\",\n",
        "        placeholder=\"Ã–rnek: AyrÄ±lÄ±k, doÄŸa, aÅŸk...\",\n",
        "        lines=1\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"Ãœretilen Åiir\",\n",
        "        lines=10,\n",
        "        max_lines=20\n",
        "    ),\n",
        "    title=\"TÃ¼rkÃ§e Åiir Ãœretici\",\n",
        "    theme=\"soft\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "M4Rh9mYEizDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}