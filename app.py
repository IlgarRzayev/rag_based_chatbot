# -*- coding: utf-8 -*-
import google.generativeai as genai
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain_text_splitters import CharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from datasets import load_dataset
import gradio as gr
import os
from dotenv import load_dotenv  # <- YENÄ° EKLENDÄ°

# .env dosyasÄ±nÄ± yÃ¼kle
load_dotenv()

# API Key'leri .env dosyasÄ±ndan al
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
HF_TOKEN = os.getenv("HF_TOKEN")

# API Key kontrolÃ¼
if not GOOGLE_API_KEY or not HF_TOKEN:
    raise ValueError("API Key'ler bulunamadÄ±! LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")

os.environ['HUGGINGFACE_HUB_TOKEN'] = HF_TOKEN
genai.configure(api_key=GOOGLE_API_KEY)

# Veri setini yÃ¼kle ve vektÃ¶r veritabanÄ±nÄ± oluÅŸtur
def initialize_system():
    print("Sistem baÅŸlatÄ±lÄ±yor...")
    
    # Veri setini yÃ¼kle
    dataset = load_dataset("aliarda/Turkish-Poems-19K", token=HF_TOKEN)
    print(f"Veri seti yÃ¼klendi! Toplam {len(dataset['train'])} ÅŸiir bulundu.")

    poems = [
        item["siir_metni"].strip()
        for item in dataset["train"]
        if item["siir_metni"] and isinstance(item["siir_metni"], str) and item["siir_metni"].strip()
    ]
    poems = poems[:1000]
    print(f"{len(poems)} ÅŸiir iÅŸleme alÄ±ndÄ±.")

    # Embedding ve vektÃ¶r veritabanÄ±
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)

    docs = []
    for p in poems:
        if p and isinstance(p, str) and p.strip():
            docs.extend(text_splitter.create_documents([p.strip()]))

    vectorstore = FAISS.from_documents(docs, embeddings)
    print("FAISS veritabanÄ± oluÅŸturuldu!")

    # LLM ve RAG zinciri
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-pro",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.8
    )

    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
        return_source_documents=True
    )

    print("Sistem hazÄ±r! Åžiir Ã¼retmeye hazÄ±rsÄ±nÄ±z")
    return qa_chain

# Sistemi baÅŸlat
qa_chain = initialize_system()

# Åžiir Ã¼retici fonksiyon
def siir_uretici(tema):
    prompt = f"""TÃ¼rkÃ§e, sanatsal ve kafiyeli bir ÅŸiir yaz.
    Åžiir ÅŸu temaya uygun olmalÄ±: '{tema}'.
    Veri tabanÄ±ndaki TÃ¼rkÃ§e ÅŸiirlerin tarzÄ±ndan esinlen:
    Åžiir Ã¶zellikleri:
    - Her dize kÄ±sa olsun (4â€“8 kelime arasÄ±)
    - Son kelimelerde kafiye uyumu bulunsun
    - Gerekirse iÃ§ uyak (iÃ§ kafiye) da kullanÄ±labilir
    - AkÄ±cÄ±, duygusal ve imgelerle dolu olsun
    - DoÄŸa ve insan temalarÄ± kullanÄ±labilir
    - Sadece ÅŸiiri yaz, aÃ§Ä±klama yapma.
    """

    try:
        response = qa_chain.invoke({"question": prompt, "chat_history": []})
        return response["answer"].strip()
    except Exception as e:
        return f"Bir hata oluÅŸtu: {str(e)}"

# Gradio arayÃ¼zÃ¼
demo = gr.Interface(
    fn=siir_uretici,
    inputs=gr.Textbox(
        label="ðŸŽ­ Åžiir TemasÄ±",
        placeholder="Ã–rnek: AyrÄ±lÄ±k, doÄŸa, aÅŸk...",
        lines=1
    ),
    outputs=gr.Textbox(
        label="Ãœretilen Åžiir",
        lines=10,
        max_lines=20
    ),
    title="TÃ¼rkÃ§e Åžiir Ãœretici - Akbank GenAI Bootcamp",
    description="RAG tabanlÄ± TÃ¼rkÃ§e ÅŸiir Ã¼retici. Bir tema yazÄ±n, AI ÅŸiir oluÅŸtursun!",
    theme="soft",
    allow_flagging="never"
)

# Render iÃ§in Ã¶zel launch
if __name__ == "__main__":
    demo.launch(
        server_name="0.0.0.0",
        server_port=int(os.environ.get("PORT", 7860)),
        share=False
    )
