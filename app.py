# -*- coding: utf-8 -*-

import google.generativeai as genai
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import ConversationalRetrievalChain
from langchain_text_splitters import CharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from datasets import load_dataset
import gradio as gr
import os

# Environment variables'dan API anahtarlarÄ±nÄ± al
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
HF_TOKEN = os.getenv("HUGGINGFACE_HUB_TOKEN")

# API anahtarlarÄ±nÄ± kontrol et
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY environment variable bulunamadÄ±!")
if not HF_TOKEN:
    raise ValueError("HUGGINGFACE_HUB_TOKEN environment variable bulunamadÄ±!")

os.environ['HUGGINGFACE_HUB_TOKEN'] = HF_TOKEN
genai.configure(api_key=GOOGLE_API_KEY)

# Veri setini yÃ¼kle
dataset = load_dataset("aliarda/Turkish-Poems-19K", token=HF_TOKEN)
print(f"Veri seti yÃ¼klendi! Toplam {len(dataset['train'])} ÅŸiir bulundu.")

poems = [
    item["siir_metni"].strip()
    for item in dataset["train"]
    if item["siir_metni"] and isinstance(item["siir_metni"], str) and item["siir_metni"].strip()
]
poems = poems[:1000]
print(f"{len(poems)} ÅŸiir iÅŸleme alÄ±ndÄ±.")

# Embedding ve vektÃ¶r veritabanÄ±
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)

docs = []
for p in poems:
    if p and isinstance(p, str) and p.strip():
        docs.extend(text_splitter.create_documents([p.strip()]))

vectorstore = FAISS.from_documents(docs, embeddings)
print("âœ… FAISS veritabanÄ± oluÅŸturuldu!")

# RAG zinciri ve LLM modeli
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    google_api_key=GOOGLE_API_KEY,
    temperature=0.8
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
    return_source_documents=True
)

print("Sistem hazÄ±r! Åiir Ã¼retmeye hazÄ±rsÄ±nÄ±z")

# Gradio arayÃ¼zÃ¼
def siir_uretici(tema):
    prompt = f"""TÃ¼rkÃ§e, sanatsal ve kafiyeli bir ÅŸiir yaz.
    Åiir ÅŸu temaya uygun olmalÄ±: '{tema}'.
    Veri tabanÄ±ndaki TÃ¼rkÃ§e ÅŸiirlerin tarzÄ±ndan esinlen:
    Åiir Ã¶zellikleri:
    - Her dize kÄ±sa olsun (4â€“8 kelime arasÄ±)
    - Son kelimelerde kafiye uyumu bulunsun
    - Gerekirse iÃ§ uyak (iÃ§ kafiye) da kullanÄ±labilir
    - AkÄ±cÄ±, duygusal ve imgelerle dolu olsun
    - DoÄŸa ve insan temalarÄ± kullanÄ±labilir
    - Sadece ÅŸiiri yaz, aÃ§Ä±klama yapma.
    """

    response = qa_chain.invoke({"question": prompt, "chat_history": []})
    return response["answer"].strip()


demo = gr.Interface(
    fn=siir_uretici,
    inputs=gr.Textbox(
        label="ğŸ­ Åiir TemasÄ±",
        placeholder="Ã–rnek: AyrÄ±lÄ±k, doÄŸa, aÅŸk...",
        lines=1
    ),
    outputs=gr.Textbox(
        label="Ãœretilen Åiir",
        lines=10,
        max_lines=20
    ),
    title="TÃ¼rkÃ§e Åiir Ãœretici",
    theme="soft",
    allow_flagging="never"
)

if __name__ == "__main__":
    demo.launch()
