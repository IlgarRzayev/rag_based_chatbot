# -*- coding: utf-8 -*-

import google.generativeai as genai
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import CharacterTextSplitter
from langchain_google_genai import ChatGoogleGenerativeAI
from datasets import load_dataset
import gradio as gr
import os

# Ortam deÄŸiÅŸkenlerinden al
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
HF_TOKEN = os.getenv("HF_TOKEN")

# EÄŸer ortam deÄŸiÅŸkeni bulunmazsa kullanÄ±cÄ±dan al
if not GOOGLE_API_KEY:
    GOOGLE_API_KEY = input("LÃ¼tfen Google Gemini API anahtarÄ±nÄ±zÄ± girin: ").strip()

if not HF_TOKEN:
    HF_TOKEN = input("LÃ¼tfen Hugging Face tokenâ€™Ä±nÄ±zÄ± girin: ").strip()

# Ortam deÄŸiÅŸkenlerine yeniden kaydet (bazÄ± kÃ¼tÃ¼phaneler buna ihtiyaÃ§ duyar)
os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
os.environ["HUGGINGFACE_HUB_TOKEN"] = HF_TOKEN



# Dataset'i private token ile yÃ¼kle
dataset = load_dataset("aliarda/Turkish-Poems-19K")
print(f"Veri seti yÃ¼klendi! Toplam {len(dataset['train'])} ÅŸiir bulundu.")

if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY environment variable bulunamadÄ±!")

genai.configure(api_key=GOOGLE_API_KEY)

poems = [
    item["siir_metni"].strip()
    for item in dataset["train"]
    if item["siir_metni"] and isinstance(item["siir_metni"], str) and item["siir_metni"].strip()
]
poems = poems[:1000]
print(f"{len(poems)} ÅŸiir iÅŸleme alÄ±ndÄ±.")

# Embedding ve vektÃ¶r veritabanÄ±
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)

docs = []
for p in poems:
    if p and isinstance(p, str) and p.strip():
        docs.extend(text_splitter.create_documents([p.strip()]))

vectorstore = FAISS.from_documents(docs, embeddings)
print("âœ… FAISS veritabanÄ± oluÅŸturuldu!")

# RAG mantÄ±ÄŸÄ±: ChatGoogleGenerativeAI + FAISS retriever
llm = ChatGoogleGenerativeAI(
    model="gemini-flash-latest",
    google_api_key=GOOGLE_API_KEY,
    temperature=0.8
)

retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

# .chains kullanmadan QA fonksiyonu oluÅŸtur
def qa_chain(question, chat_history=[]):
    docs = retriever.invoke(question)
    context = "\n\n".join([d.page_content for d in docs])
    prompt_text = f"Soru: {question}\n\nBaÄŸlam:\n{context}\n\nCevap:"
    response = llm.invoke(prompt_text)
    return response


print("Sistem hazÄ±r! Åiir Ã¼retmeye hazÄ±rsÄ±nÄ±z")

# Gradio arayÃ¼zÃ¼
def siir_uretici(tema):
    prompt = f"""TÃ¼rkÃ§e, sanatsal ve kafiyeli bir ÅŸiir yaz.
    Åiir ÅŸu temaya uygun olmalÄ±: '{tema}'.
    Veri tabanÄ±ndaki TÃ¼rkÃ§e ÅŸiirlerin tarzÄ±ndan esinlen:
    Åiir Ã¶zellikleri:
    - Her dize kÄ±sa olsun (4â€“8 kelime arasÄ±)
    - Son kelimelerde kafiye uyumu bulunsun
    - Gerekirse iÃ§ uyak (iÃ§ kafiye) da kullanÄ±labilir
    - AkÄ±cÄ±, duygusal ve imgelerle dolu olsun
    - DoÄŸa ve insan temalarÄ± kullanÄ±labilir
    - Sadece ÅŸiiri yaz, aÃ§Ä±klama yapma.
    """

    response = qa_chain(prompt, chat_history=[])
    return response.content.strip()


demo = gr.Interface(
    fn=siir_uretici,
    inputs=gr.Textbox(
        label="ğŸ­ Åiir TemasÄ±",
        placeholder="Ã–rnek: AyrÄ±lÄ±k, doÄŸa, aÅŸk...",
        lines=1
    ),
    outputs=gr.Textbox(
        label="Ãœretilen Åiir",
        lines=10,
        max_lines=20
    ),
    title="TÃ¼rkÃ§e Åiir Ãœretici",
    theme="soft",
    allow_flagging="never"
)

if __name__ == "__main__":
    demo.launch()
